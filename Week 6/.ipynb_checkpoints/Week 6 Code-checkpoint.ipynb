{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Using this notebook\n",
    "This notebook walks through the available data, and introduces you to the concepts and tools that you can use in order to prepare, propose, and solve data science problems. Each code cell in this tool can be executed to replicate the results. \n",
    "\n",
    "For tips/tricks on using Jupyter Notebooks, please see: https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Notebook%20Basics.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages\n",
    "Pandas: To Play with data frames (kind of like Excel for Python)\n",
    "\n",
    "Numpy: For numerical operation\n",
    "\n",
    "glob: For file system operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the data from the previous week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_with_target = pd.read_csv(\"../Week 5/full_data_with_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "We are now ready to use this dataset with the defined target (i.e. output) and features (i.e. input) and create a model. We will use a Random Forest Classifier available through the python Scikit-learn library and evaluate the performance of this model. \n",
    "\n",
    "### Train and Test Split\n",
    "To evaluate the performance of any model, we need data for which the truth is known (i.e. we need to hold out a subset of our prepared data that the model doesn't see) so that we can evaluate the performance of the model. Otherwise, we will have to wait until we see new data and will not know if our model is any good. \n",
    "\n",
    "Let's finish processing our prepred data for modeling and create the training and testing splits. \n",
    "\n",
    "Following convention, we will denote our inputs with X and our outputs with y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_na_condition = (training_data_with_target[\"ratio_up10days\"].isna()) | (training_data_with_target[\"beat\"].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all cases where an input feature is NA/Null\n",
    "training_data_with_target = training_data_with_target[~is_na_condition]\n",
    "\n",
    "#Split into X and Y\n",
    "X = training_data_with_target.reset_index()[['ratio_updays','ratio_up10days','ratio_up60days',\n",
    "                                             'upday_50','upday10_50','upday60_50',\n",
    "                                             'ratio_up_return','ratio_up_volume',]]\n",
    "y = training_data_with_target.reset_index()[\"beat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio_updays</th>\n",
       "      <th>ratio_up10days</th>\n",
       "      <th>ratio_up60days</th>\n",
       "      <th>upday_50</th>\n",
       "      <th>upday10_50</th>\n",
       "      <th>upday60_50</th>\n",
       "      <th>ratio_up_return</th>\n",
       "      <th>ratio_up_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.264706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.241935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.435484</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.209677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.295082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.245902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.241935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.262295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratio_updays  ratio_up10days  ratio_up60days  upday_50  upday10_50  \\\n",
       "0      0.352941        0.382353        0.382353       0.0         0.0   \n",
       "1      0.629032        0.725806        0.387097       1.0         1.0   \n",
       "2      0.421875        0.515625        0.906250       0.0         1.0   \n",
       "3      0.507692        0.615385        0.676923       1.0         1.0   \n",
       "4      0.500000        0.435484        0.274194       0.0         0.0   \n",
       "5      0.442623        0.426230        0.245902       0.0         0.0   \n",
       "6      0.437500        0.406250        0.718750       0.0         0.0   \n",
       "7      0.475410        0.311475        0.049180       0.0         0.0   \n",
       "8      0.516129        0.580645        0.822581       1.0         1.0   \n",
       "9      0.475410        0.573770        0.918033       0.0         1.0   \n",
       "\n",
       "   upday60_50  ratio_up_return  ratio_up_volume  \n",
       "0         0.0         0.264706         0.264706  \n",
       "1         0.0         0.483871         0.241935  \n",
       "2         1.0         0.375000         0.265625  \n",
       "3         1.0         0.430769         0.230769  \n",
       "4         0.0         0.387097         0.209677  \n",
       "5         0.0         0.311475         0.295082  \n",
       "6         1.0         0.359375         0.218750  \n",
       "7         0.0         0.327869         0.245902  \n",
       "8         1.0         0.403226         0.241935  \n",
       "9         1.0         0.327869         0.262295  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5    1.0\n",
       "6    0.0\n",
       "7    0.0\n",
       "8    1.0\n",
       "9    1.0\n",
       "Name: beat, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's import the train and test split from sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have split the inputs and outputs and now we can use the train_test_split function to put 90% of the data into X_train, and 10% into X_test (and corresponding values for y as well). We have taken the additional step here to \n",
    "stratify our sampling across the ticker codes (i.e. we want to make sure that our 90% and 10% split of the overall data contain the same relative proportion of companies). It is important to stratify the dataset when sub-populations are involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.9, test_size = 0.1,\n",
    "                                                    stratify = training_data_with_target.reset_index()[\"ticker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building\n",
    "Let's use the scikit learn RandomForest classifier to build our model using X_train and y_train. We will use certain parameters for our classifier - you should read up on the significance of these classifiers and try changing them to see the effect of those on the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the package\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Initialize a classifier \n",
    "clf = RandomForestClassifier(n_estimators=10000, max_depth=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10000, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Testing\n",
    "Now that we have fit the model to the training data, let's see how we can use this model to create prdictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use clf.predict to get the predictions\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the predictions to the original data subset \n",
    "subset = training_data_with_target.reset_index().loc[y_test.index]\n",
    "subset[\"predicted\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ticker</th>\n",
       "      <th>fiscal_year</th>\n",
       "      <th>fiscal_quarter</th>\n",
       "      <th>ratio_updays</th>\n",
       "      <th>ratio_up10days</th>\n",
       "      <th>ratio_up60days</th>\n",
       "      <th>upday_50</th>\n",
       "      <th>upday10_50</th>\n",
       "      <th>upday60_50</th>\n",
       "      <th>ratio_up_return</th>\n",
       "      <th>ratio_up_volume</th>\n",
       "      <th>beat</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>683</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>1200</td>\n",
       "      <td>INTC</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>1275</td>\n",
       "      <td>INTU</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>1969</td>\n",
       "      <td>SYMC</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>465</td>\n",
       "      <td>ATVI</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>0.460317</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>1087</td>\n",
       "      <td>FTR</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>155</td>\n",
       "      <td>ADP</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1315</td>\n",
       "      <td>KLAC</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>1521</td>\n",
       "      <td>MCHP</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>2057</td>\n",
       "      <td>VRSN</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.301587</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index ticker  fiscal_year  fiscal_quarter  ratio_updays  ratio_up10days  \\\n",
       "673     683   CSCO         2006               2      0.412698        0.349206   \n",
       "1184   1200   INTC         2008               3      0.515625        0.468750   \n",
       "1258   1275   INTU         2012               2      0.428571        0.634921   \n",
       "1938   1969   SYMC         2008               4      0.459016        0.344262   \n",
       "458     465   ATVI         2011               4      0.460317        0.476190   \n",
       "1073   1087    FTR         2006               2      0.421875        0.484375   \n",
       "154     155    ADP         2008               4      0.587302        0.555556   \n",
       "1297   1315   KLAC         2007               2      0.587302        0.650794   \n",
       "1499   1521   MCHP         2013               4      0.568966        0.534483   \n",
       "2026   2057   VRSN         2000               4      0.476190        0.301587   \n",
       "\n",
       "      ratio_up60days  upday_50  upday10_50  upday60_50  ratio_up_return  \\\n",
       "673         0.253968       0.0         0.0         0.0         0.063492   \n",
       "1184        0.468750       1.0         0.0         0.0         0.187500   \n",
       "1258        0.873016       0.0         1.0         1.0         0.142857   \n",
       "1938        0.377049       0.0         0.0         0.0         0.245902   \n",
       "458         0.190476       0.0         0.0         0.0         0.174603   \n",
       "1073        0.718750       0.0         0.0         1.0         0.109375   \n",
       "154         0.809524       1.0         1.0         1.0         0.174603   \n",
       "1297        1.000000       1.0         1.0         1.0         0.253968   \n",
       "1499        0.862069       1.0         1.0         1.0         0.137931   \n",
       "2026        0.428571       0.0         0.0         0.0         0.333333   \n",
       "\n",
       "      ratio_up_volume  beat  predicted  \n",
       "673          0.285714   1.0        1.0  \n",
       "1184         0.171875   0.0        1.0  \n",
       "1258         0.174603   1.0        1.0  \n",
       "1938         0.262295   1.0        1.0  \n",
       "458          0.222222   1.0        1.0  \n",
       "1073         0.218750   1.0        1.0  \n",
       "154          0.206349   1.0        1.0  \n",
       "1297         0.238095   1.0        1.0  \n",
       "1499         0.258621   1.0        1.0  \n",
       "2026         0.317460   1.0        1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's look at our predictions, lined up with the actual data\n",
    "subset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that our model primarily predicts that actual EPS will beat concensus. This is not surprising considering the very basic strategy of always saying beat will give you 66% accuracy. However, we need to evaluate how our model is actually doing on our entire sample. For this, we need to consider a few metrics\n",
    "\n",
    "##### Precision\n",
    "Precision looks at how often our model has false positives. This is represented by the formula: (Number of Predicted Actual Positives)/(/Total number of Predicted Positives). Higher value in this case is better, since it means that we have very little actual 0’s falsely classified as 1’s.\n",
    "\n",
    "##### Recall \n",
    "Recall looks at how sensitive our model is. It seeks to answer the question – how many of the actual 1’s did we correctly identify.\n",
    "This is represented by the formula: (Number of Predicted Actual Positives)/(/Total number of Actual Positives). Here too, higher number is better, as it means that we have fewer actual 0’s classified as 1’s.\n",
    "\n",
    "##### Accuracy \n",
    "Accuracy looks to answer the question – how often do we make the right decision. In other words, does model correctly classify 1’s when actual value is 1, and 0’s when actual value is 0. This is captured in the formula :    (Number of Correct Examples / )/(Total number of Examples)  . This metric is however sensitive to imbalanced classes (cases when number of 1’s is greater than 0’s, as is the case here since companies more often beat consensus estimates based on the way we calculate a beat)\n",
    "\n",
    "\n",
    "We can use the sklearn libraries with built-in functions to calculate these, and calculate our models accuracy, precision, and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Precision: 0.752222\n",
      "Model Recall: 0.980944\n",
      "Model Accuracy: 0.752389\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Precision: %f\"%prec)\n",
    "print(\"Model Recall: %f\"%rec)\n",
    "print(\"Model Accuracy: %f\"%acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "We can see here that we improve on the baseline (66%) precision and accuracy by 9%. Furthermore, we improve this baseline without sacrificing much in the way of recall. \n",
    "\n",
    "In human judgement, we trade off heavily between precision and recall - e.g. saying every stock is going to beat eestimates every quarter is a recall of 1 (since you get the actual beats right 100% of the time). However, the recall suffers substantially (only 66% of the predictions will be accurate). In this model, we trade off 2% of the recall (100% to 98.1%) for a 9% increase in recall. This is a great start and the increased accuracy can be leveraged in trading models to create efficient portfolios with high returns. \n",
    "\n",
    "The model can be improved by trying alternative methods (such as RNNs, CNNs, XGBoost, Ensemble Models, etc.) and creating more features (using hypotheses and data) as we demonstrated. These steps should be taken incrementally with an eye on the precision and recall tradeoffs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
